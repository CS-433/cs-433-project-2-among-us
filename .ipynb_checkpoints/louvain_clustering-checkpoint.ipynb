{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datapreprocessing\n",
    "* From CSV to Feather\n",
    "* Drop NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\newbi\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\users\\newbi\\anaconda3\\lib\\site-packages (from pyarrow) (1.18.5)\n",
      "Collecting python-louvain\n",
      "  Downloading python-louvain-0.14.tar.gz (19 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\newbi\\anaconda3\\lib\\site-packages (from python-louvain) (2.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\newbi\\anaconda3\\lib\\site-packages (from python-louvain) (1.18.5)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\newbi\\anaconda3\\lib\\site-packages (from networkx->python-louvain) (4.4.2)\n",
      "Building wheels for collected packages: python-louvain\n",
      "  Building wheel for python-louvain (setup.py): started\n",
      "  Building wheel for python-louvain (setup.py): finished with status 'done'\n",
      "  Created wheel for python-louvain: filename=python_louvain-0.14-py3-none-any.whl size=9294 sha256=15434e6ae7922dc512c8df456dcea691385bdcc96e1e4ed4b356c064752a6015\n",
      "  Stored in directory: c:\\users\\newbi\\appdata\\local\\pip\\cache\\wheels\\22\\f9\\ce\\591ffa9b16851da50ca337c9ecfd44d79a7b87fcbd2a7a0021\n",
      "Successfully built python-louvain\n",
      "Installing collected packages: python-louvain\n",
      "Successfully installed python-louvain-0.14\n"
     ]
    }
   ],
   "source": [
    "# Install packages using pip in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install pyarrow\n",
    "!{sys.executable} -m pip install python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newbi\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# this block does not need to be run if the feather file already exists\n",
    "#usual lines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import path\n",
    "input_path = 'Data/us-equities_logreturns.csv'\n",
    "output_path = 'Data/us-equities_logreturns.feather'\n",
    "\n",
    "#load data\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "#delete columns with NaN values\n",
    "df_clean = df.dropna(axis=1, how=\"any\", thresh=None, subset=None, inplace=False)\n",
    "df_clean.drop(columns=\"Unnamed: 0\",inplace=True)\n",
    "\n",
    "# keep track of how many columns we have lost\n",
    "columns_losses = df_clean.shape[1] - df.shape[1]\n",
    "\n",
    "#write to feather \n",
    "df_clean.to_feather(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Louvain clustering for correlation matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import networkx as nx\n",
    "import community\n",
    "\n",
    "\n",
    "def compute_C_minus_C0(lambdas,v,lambda_plus):\n",
    "    N=len(lambdas)\n",
    "    C_clean=np.zeros((N, N))\n",
    "  \n",
    "    # _s stands for _structure below. Note that range(N-1) means that we do not include the maximum eigenvalue\n",
    "    for i in range(N-1):\n",
    "        if lambdas[i]>lambda_plus:\n",
    "            C_clean=C_clean + lambdas[i]*(np.outer(v[:,i],v[:,i]))\n",
    "    np.fill_diagonal(C_clean,1)\n",
    "    return C_clean    \n",
    "    \n",
    "    \n",
    "def LouvainCorrelationClustering(R):   # R is a matrix of return\n",
    "    N=R.shape[1]\n",
    "    T=R.shape[0]\n",
    "\n",
    "    q=N*1./T\n",
    "    lambda_plus=(1.+np.sqrt(q))**2\n",
    "\n",
    "    C=R.corr()\n",
    "    lambdas, v = LA.eigh(C)\n",
    "    \n",
    "    C_s=compute_C_minus_C0(lambdas,v,lambda_plus)\n",
    "    C_s=np.abs(C_s)\n",
    "    \n",
    "    mygraph= nx.from_numpy_matrix(C_s)\n",
    "    partition = community.community_louvain.best_partition(mygraph)\n",
    "\n",
    "    DF=pd.DataFrame.from_dict(partition,orient=\"index\")\n",
    "    return(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assets:\n",
      "      0\n",
      "AEP  0\n",
      "FL   1\n",
      "MRO  2\n",
      "DTE  0\n",
      "IP   3\n",
      "..  ..\n",
      "SWM  8\n",
      "ITT  7\n",
      "MSM  0\n",
      "HIG  2\n",
      "BCO  4\n",
      "\n",
      "[481 rows x 1 columns]\n",
      "\n",
      "Assets values are: [0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# Define clustering Assets\n",
    "R=pd.read_feather(\"Data/us-equities_logreturns.feather\")     \n",
    "myclusteringAssets=LouvainCorrelationClustering(R)\n",
    "myclusteringAssets.index=R.columns\n",
    "print(\"Assets:\\n\",myclusteringAssets)\n",
    "print(\"\\nAssets values are:\",np.unique(myclusteringAssets.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a local period and compare the assets \n",
    "* R.shape  = (4549, 481) \n",
    "* each row = one day\n",
    "* after a week t0 = 0 and t1= 7, we have decend numbers.\n",
    "* do we have to keep tracks like 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of states:\n",
      "      state\n",
      "AEP      0\n",
      "FL       1\n",
      "MRO      1\n",
      "DTE      0\n",
      "IP       2\n",
      "..     ...\n",
      "SWM      2\n",
      "ITT      3\n",
      "MSM      1\n",
      "HIG      2\n",
      "BCO      1\n",
      "\n",
      "[481 rows x 1 columns]\n",
      "\n",
      "Unique state values are: [0 1 2 3]\n",
      "\n",
      "The string of states from t0: 1 and t1: 51 is:\n",
      " 0,1,1,0,2,0,3,0,2,1,3,3,0,2,3,3,2,1,3,0,3,2,1,3,1,1,0,2,1,1,0,3,2,0,1,3,0,3,2,2,2,1,0,1,1,3,0,1,0,3,0,1,2,2,3,2,1,3,1,0,0,0,1,2,2,0,2,1,1,2,3,2,0,3,1,0,0,3,2,3,1,2,1,0,0,0,3,2,1,0,0,3,2,3,2,0,0,1,0,3,3,2,3,2,1,2,0,0,2,0,2,2,2,3,3,0,0,3,1,3,3,1,3,1,1,1,0,2,1,3,3,1,2,2,0,3,2,0,0,3,3,3,0,1,1,0,3,1,2,1,2,2,2,2,2,1,1,3,0,2,3,2,1,2,3,1,3,2,2,1,0,0,0,0,1,2,3,1,0,3,2,0,3,2,1,3,2,1,2,0,0,2,0,1,0,0,2,2,3,0,1,2,2,2,1,1,3,2,1,3,1,3,2,1,2,1,0,2,2,3,0,3,1,2,1,1,2,2,0,2,3,1,1,2,1,0,3,2,0,0,1,2,2,3,2,1,0,2,3,0,1,1,1,3,0,1,2,1,3,0,2,1,1,3,2,1,2,0,1,1,0,0,1,3,2,2,3,1,3,2,3,0,1,3,1,0,2,0,2,3,1,1,1,3,1,1,1,1,1,0,2,3,2,2,3,3,2,1,2,0,3,0,3,3,1,1,0,0,3,1,1,1,0,2,2,3,1,1,0,2,0,3,0,1,3,1,0,2,2,1,0,3,0,1,3,2,2,2,2,2,3,1,2,2,3,0,1,3,3,2,2,2,2,0,3,2,1,3,1,2,2,1,1,0,3,2,3,1,2,2,2,2,3,3,1,3,2,2,0,2,1,0,0,2,3,2,2,3,2,2,0,2,2,3,1,0,1,0,2,2,1,0,0,0,0,1,1,1,3,2,2,3,0,1,2,0,1,0,0,1,3,2,1,1,1,0,0,3,1,2,1,2,3,1,1,2,1,2,1,0,2,1,1,1,3,1,2,2,3,1,3,3,0,1,0,3,1,0,1,2,1,1,2,0,1,0,2,3,1,2,1\n"
     ]
    }
   ],
   "source": [
    "# set the time period\n",
    "t0=1 #starting period\n",
    "t1=51 #50 days on memory\n",
    "Rlocal=R[t0:t1].copy()\n",
    "myclusteringDays=LouvainCorrelationClustering(Rlocal)\n",
    "myclusteringDays.index=Rlocal.columns\n",
    "myclusteringDays.columns=[\"state\"]\n",
    "string_states = ','.join(map(str, myclusteringDays['state']))\n",
    "print(\"List of states:\\n\",myclusteringDays)\n",
    "print(\"\\nUnique state values are:\",np.unique(myclusteringDays.values))\n",
    "print(\"\\nThe string of states from t0:\",t0,\"and t1:\",t1,\"is:\\n\",string_states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
